{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4: Logistic Regression and Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "\n",
    "# Reading from train file\n",
    "with open('LRTrain.csv', 'r', newline='') as LRTrain:\n",
    "    reader = csv.reader(LRTrain)\n",
    "\n",
    "df = pd.read_csv(\"LRTrain.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Separating independent and dependent variables\n",
    "x = df.iloc[:, :30]\n",
    "y = df.iloc[:, 30]\n",
    "\n",
    "# Standardizing x \n",
    "x = (x - x.mean())/x.std()\n",
    "\n",
    "# Re-shaping y\n",
    "y = y.values.reshape(y.shape[0],1)\n",
    "\n",
    "#Reading from test file\n",
    "\n",
    "with open('LRTest.csv', 'r', newline='') as LRTest:\n",
    "    reader = csv.reader(LRTest)\n",
    "\n",
    "df_test = pd.read_csv(\"LRTest.csv\")\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "#Separating features and diagnosis\n",
    "\n",
    "x_test = df_test.iloc[:, :30]\n",
    "y_test = df_test.iloc[:, 30]\n",
    "\n",
    "# Standardizing x \n",
    "x_test = (x_test - x_test.mean())/x_test.std()\n",
    "\n",
    "# Reshaping y\n",
    "y_test = y_test.values.reshape(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(w,x,y):\n",
    "    \n",
    "    n = x.shape[0]\n",
    "        \n",
    "    mul = np.dot(x,w)\n",
    "    ypred = 1/(1+np.exp(-mul))\n",
    "    cost = -np.sum(y*np.log(ypred) - (1-y)*np.log(1-ypred))/n     \n",
    "    dif = mul - y\n",
    "    gradient  = np.dot(np.transpose(x),dif)/n\n",
    "    \n",
    "    return gradient,cost,ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_reg(w,X,Y,gamma,steps):\n",
    "   \n",
    "\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        gradient, cost,ypred = gradient_descent(w,X,Y)\n",
    "        w  = w - gamma*gradient\n",
    "        \n",
    "        if(i%100==0):\n",
    "            costs.append(cost)\n",
    "            \n",
    "    return w,gradient,costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trial 1: 0.7435100885520322\n",
      "[[ 6.25287654e-03]\n",
      " [ 2.83592727e-03]\n",
      " [ 6.35472705e-03]\n",
      " [ 6.05226075e-03]\n",
      " [ 3.28137322e-03]\n",
      " [ 4.90946445e-03]\n",
      " [ 5.72008656e-03]\n",
      " [ 6.63102260e-03]\n",
      " [ 2.55726591e-03]\n",
      " [-4.37665074e-04]\n",
      " [ 4.81163179e-03]\n",
      " [-7.95763463e-04]\n",
      " [ 4.82378245e-03]\n",
      " [ 4.56741585e-03]\n",
      " [-3.70933615e-04]\n",
      " [ 2.00360679e-03]\n",
      " [ 1.85675993e-03]\n",
      " [ 3.36406146e-03]\n",
      " [-2.09145404e-04]\n",
      " [-9.41681822e-05]\n",
      " [ 6.68195864e-03]\n",
      " [ 3.23677264e-03]\n",
      " [ 6.76025192e-03]\n",
      " [ 6.24146076e-03]\n",
      " [ 3.79020132e-03]\n",
      " [ 5.05559039e-03]\n",
      " [ 5.73972041e-03]\n",
      " [ 6.83356131e-03]\n",
      " [ 3.52106816e-03]\n",
      " [ 2.41732758e-03]]\n",
      " Trial 2: 0.7300883864905574\n",
      " Trial 3: 0.6258994860126317\n",
      " Trial 4: 0.721091509293773\n",
      " Trial 5: 0.6384423092454864\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros((x.shape[1],1))\n",
    "\n",
    "w,gradient,costs = logistic_reg(w,x,y,0.00001,2000)\n",
    "print(f' Trial 1: {np.linalg.norm(costs)}')\n",
    "print(w)\n",
    "w2,gradient2,costs2 = logistic_reg(w,x,y,0.0001,2000)\n",
    "print(f' Trial 2: {np.linalg.norm(costs2)}')\n",
    "\n",
    "w3,gradient3,costs3 = logistic_reg(w,x,y,0.0005,1500)\n",
    "print(f' Trial 3: {np.linalg.norm(costs3)}')\n",
    "\n",
    "w4,gradient4,costs4 = logistic_reg(w,x,y,0.001,2000)\n",
    "print(f' Trial 4: {np.linalg.norm(costs4)}')\n",
    "\n",
    "w5,gradient5,costs5 = logistic_reg(w,x,y,0.00005,1500)\n",
    "print(f' Trial 5: {np.linalg.norm(costs5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the lowest cost was in Trial 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-96fd3b3055c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Values chosen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwbest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.00999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Value: '\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-bcb77838e8ae>\u001b[0m in \u001b[0;36mlogistic_reg\u001b[0;34m(w, X, Y, gamma, steps)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mw\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'dict'"
     ]
    }
   ],
   "source": [
    "#Values chosen\n",
    "wbest,gradient,costs = logistic_reg(w,x,y,0.00999,2000)\n",
    "print('Best Value: ' ,np.linalg.norm(costs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_pred, y_test):\n",
    "    t = len(y_test)\n",
    "    \n",
    "    tp  = 0\n",
    "    p = 0\n",
    "    fp = 0\n",
    "    n = 0\n",
    "    \n",
    "    for i in range(t):\n",
    "        if y_pred[i] == 1 and y_test[i]==1:\n",
    "            tp += 1\n",
    "    \n",
    "    for i in range(t):\n",
    "        if y_test[i] == 1:\n",
    "            p += 1\n",
    "\n",
    "    for i in range(t):\n",
    "        if y_pred[i] == 1 and y_test[i]==0:\n",
    "            fp += 1\n",
    "    \n",
    "    for i in range(t):\n",
    "        if y_test[i] == 0:\n",
    "            n += 1\n",
    "    \n",
    "    tpr = tp/p\n",
    "    fpr = fp/n\n",
    "    tnr = 1 - fpr\n",
    "    fnr = 1 - tpr\n",
    "    \n",
    "    return(tpr, fpr, tnr, fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = gradient_descent(wbest,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00359748],\n",
       "        [-0.00517422],\n",
       "        [-0.00181491],\n",
       "        [ 0.00556865],\n",
       "        [-0.00133835],\n",
       "        [ 0.01018863],\n",
       "        [ 0.00548764],\n",
       "        [-0.0059605 ],\n",
       "        [ 0.00599031],\n",
       "        [ 0.01221758],\n",
       "        [-0.00047365],\n",
       "        [-0.00242208],\n",
       "        [ 0.00624872],\n",
       "        [ 0.02251898],\n",
       "        [-0.01799287],\n",
       "        [ 0.01366594],\n",
       "        [ 0.01108231],\n",
       "        [-0.00438037],\n",
       "        [-0.0016134 ],\n",
       "        [ 0.00667886],\n",
       "        [-0.00888156],\n",
       "        [-0.01069891],\n",
       "        [-0.00657028],\n",
       "        [ 0.00549895],\n",
       "        [-0.01438851],\n",
       "        [-0.00378051],\n",
       "        [-0.00335214],\n",
       "        [-0.01309826],\n",
       "        [-0.00979916],\n",
       "        [-0.01007979]]),\n",
       " -0.1607719168337483,\n",
       " array([[-0.43252333],\n",
       "        [-0.52416072],\n",
       "        [-0.48036468],\n",
       "        [-0.57501747],\n",
       "        [-0.4416985 ],\n",
       "        [-0.45621302],\n",
       "        [-0.57357726],\n",
       "        [-0.45403487],\n",
       "        [-0.45386697],\n",
       "        [-0.65718   ],\n",
       "        [-0.6025878 ],\n",
       "        [-0.46707973],\n",
       "        [-0.48029005],\n",
       "        [-0.59844674],\n",
       "        [-0.48852275],\n",
       "        [-0.35688185],\n",
       "        [-0.39272021],\n",
       "        [-0.43571904],\n",
       "        [-0.43448967],\n",
       "        [-0.60343991],\n",
       "        [-0.32115914],\n",
       "        [-0.64054552],\n",
       "        [-0.64257972],\n",
       "        [-0.41260311],\n",
       "        [-0.66211592],\n",
       "        [-0.45664861],\n",
       "        [-0.52708195],\n",
       "        [-0.41648772],\n",
       "        [-0.37677848],\n",
       "        [-0.44689898],\n",
       "        [-0.47504705],\n",
       "        [-0.53997053],\n",
       "        [-0.46224063],\n",
       "        [-0.49129883],\n",
       "        [-0.386244  ],\n",
       "        [-0.45772135],\n",
       "        [-0.43668819],\n",
       "        [-0.68231282],\n",
       "        [-0.5093321 ],\n",
       "        [-0.73159824],\n",
       "        [-0.65419338],\n",
       "        [-0.42452838],\n",
       "        [-0.4504754 ],\n",
       "        [-0.45107293],\n",
       "        [-0.42891966],\n",
       "        [-0.64002481],\n",
       "        [-0.4883263 ],\n",
       "        [-0.50931079],\n",
       "        [-0.46257801],\n",
       "        [-0.38107907],\n",
       "        [-0.64867758],\n",
       "        [-0.7416449 ],\n",
       "        [-0.4563289 ],\n",
       "        [-0.4496372 ],\n",
       "        [-0.5824355 ],\n",
       "        [-0.68354311],\n",
       "        [-0.66633379],\n",
       "        [-0.47546244],\n",
       "        [-0.51074884],\n",
       "        [-0.44972899],\n",
       "        [-0.44470138],\n",
       "        [-0.46111515],\n",
       "        [-0.42894201],\n",
       "        [-0.42337159],\n",
       "        [-0.53260062],\n",
       "        [-0.49895916],\n",
       "        [-0.47375656],\n",
       "        [-0.60646794],\n",
       "        [-0.39908545],\n",
       "        [-0.43799347],\n",
       "        [-0.56417504],\n",
       "        [-0.42262288],\n",
       "        [-0.41267184],\n",
       "        [-0.60032778],\n",
       "        [-0.53698661],\n",
       "        [-0.39467305],\n",
       "        [-0.3944264 ],\n",
       "        [-0.48915053],\n",
       "        [-0.42136699],\n",
       "        [-0.50173453],\n",
       "        [-0.45393085],\n",
       "        [-0.57719897],\n",
       "        [-0.49400618],\n",
       "        [-0.58994909],\n",
       "        [-0.59576345],\n",
       "        [-0.49114347],\n",
       "        [-0.38690689],\n",
       "        [-0.45161426],\n",
       "        [-0.60322946],\n",
       "        [-0.63038697],\n",
       "        [-0.60974281],\n",
       "        [-0.53839804],\n",
       "        [-0.4487236 ],\n",
       "        [-0.45313924],\n",
       "        [-0.67099614],\n",
       "        [-0.63472978],\n",
       "        [-0.46624546],\n",
       "        [-0.39716009],\n",
       "        [-0.43062983],\n",
       "        [-0.58890253],\n",
       "        [-0.66835563],\n",
       "        [-0.44520495],\n",
       "        [-0.57941574],\n",
       "        [-0.43176208],\n",
       "        [-0.42922038],\n",
       "        [-0.69777599],\n",
       "        [-0.42546996],\n",
       "        [-0.66810165],\n",
       "        [-0.52276834],\n",
       "        [-0.6201448 ],\n",
       "        [-0.42228217],\n",
       "        [-0.41334735],\n",
       "        [-0.51799792],\n",
       "        [-0.34363787],\n",
       "        [-0.60186194],\n",
       "        [-0.4405177 ],\n",
       "        [-0.5839353 ],\n",
       "        [-0.45499181],\n",
       "        [-0.41117311],\n",
       "        [-0.39690805],\n",
       "        [-0.42780201],\n",
       "        [-0.3795796 ],\n",
       "        [-0.39747545],\n",
       "        [-0.50951212],\n",
       "        [-0.6442367 ],\n",
       "        [-0.50981594],\n",
       "        [-0.56950288],\n",
       "        [-0.44587598],\n",
       "        [-0.57411882],\n",
       "        [-0.37661158],\n",
       "        [-0.45333855],\n",
       "        [-0.39752614],\n",
       "        [-0.40447196],\n",
       "        [-0.606331  ],\n",
       "        [-0.65476342],\n",
       "        [-0.60616575],\n",
       "        [-0.40996918],\n",
       "        [-0.46080436],\n",
       "        [-0.42572732],\n",
       "        [-0.40127952],\n",
       "        [-0.51666224],\n",
       "        [-0.46135042],\n",
       "        [-0.37416423],\n",
       "        [-0.51382243],\n",
       "        [-0.43328917],\n",
       "        [-0.52077147],\n",
       "        [-0.46205937],\n",
       "        [-0.4464647 ],\n",
       "        [-0.7165559 ],\n",
       "        [-0.55376407],\n",
       "        [-0.55806318],\n",
       "        [-0.45813039],\n",
       "        [-0.39646177],\n",
       "        [-0.67228068],\n",
       "        [-0.56010624],\n",
       "        [-0.61345883],\n",
       "        [-0.82777359],\n",
       "        [-0.35175666],\n",
       "        [-0.42385819],\n",
       "        [-0.56288369],\n",
       "        [-0.61076502],\n",
       "        [-0.43083761],\n",
       "        [-0.43993436],\n",
       "        [-0.60972941],\n",
       "        [-0.53194104],\n",
       "        [-0.45553831],\n",
       "        [-0.40556042],\n",
       "        [-0.48069171],\n",
       "        [-0.43464045],\n",
       "        [-0.48473621],\n",
       "        [-0.56194107],\n",
       "        [-0.4269011 ],\n",
       "        [-0.41205797],\n",
       "        [-0.62505611],\n",
       "        [-0.45274439],\n",
       "        [-0.44358542],\n",
       "        [-0.42800301],\n",
       "        [-0.43202573],\n",
       "        [-0.4115837 ],\n",
       "        [-0.5810655 ],\n",
       "        [-0.58755932],\n",
       "        [-0.59348981],\n",
       "        [-0.3962189 ],\n",
       "        [-0.4533605 ],\n",
       "        [-0.41992657],\n",
       "        [-0.64986466],\n",
       "        [-0.63169991],\n",
       "        [-0.56070326],\n",
       "        [-0.63992601],\n",
       "        [-0.38873053],\n",
       "        [-0.42579261],\n",
       "        [-0.43285621],\n",
       "        [-0.47850945],\n",
       "        [-0.67101498],\n",
       "        [-0.44336631],\n",
       "        [-0.3939074 ],\n",
       "        [-0.38485698],\n",
       "        [-0.72114883],\n",
       "        [-0.61355308],\n",
       "        [-0.67526467],\n",
       "        [-0.39592577],\n",
       "        [-0.51333905],\n",
       "        [-0.48655951],\n",
       "        [-0.41340269],\n",
       "        [-0.54519371],\n",
       "        [-0.47046849],\n",
       "        [-0.44095132],\n",
       "        [-0.51702337],\n",
       "        [-0.56439947],\n",
       "        [-0.51868041],\n",
       "        [-0.40485684],\n",
       "        [-0.4238324 ],\n",
       "        [-0.35574256],\n",
       "        [-0.65452111],\n",
       "        [-0.639373  ],\n",
       "        [-0.42254828],\n",
       "        [-0.46196765],\n",
       "        [-0.45392048],\n",
       "        [-0.63219686],\n",
       "        [-0.4779805 ],\n",
       "        [-0.43901876],\n",
       "        [-0.60981862],\n",
       "        [-0.55558805],\n",
       "        [-0.446601  ],\n",
       "        [-0.3986557 ],\n",
       "        [-0.42056569],\n",
       "        [-0.47924182],\n",
       "        [-0.73224147],\n",
       "        [-0.42081657],\n",
       "        [-0.4189853 ],\n",
       "        [-0.46996232],\n",
       "        [-0.42660797],\n",
       "        [-0.40592181],\n",
       "        [-0.41261688],\n",
       "        [-0.4420971 ],\n",
       "        [-0.42173491],\n",
       "        [-0.56956572],\n",
       "        [-0.55343561],\n",
       "        [-0.43890911],\n",
       "        [-0.45076226],\n",
       "        [-0.43235197],\n",
       "        [-0.34515798],\n",
       "        [-0.45424613],\n",
       "        [-0.41061528],\n",
       "        [-0.44656823],\n",
       "        [-0.37795588],\n",
       "        [-0.57337852],\n",
       "        [-0.44885521],\n",
       "        [-0.46085806],\n",
       "        [-0.50066734],\n",
       "        [-0.40726258],\n",
       "        [-0.47845872],\n",
       "        [-0.54969851],\n",
       "        [-0.41702111],\n",
       "        [-0.50865636],\n",
       "        [-0.50090346],\n",
       "        [-0.4159261 ],\n",
       "        [-0.55132835],\n",
       "        [-0.42600492],\n",
       "        [-0.42655953],\n",
       "        [-0.42260671],\n",
       "        [-0.45046015],\n",
       "        [-0.60609054],\n",
       "        [-0.43913922],\n",
       "        [-0.52359618],\n",
       "        [-0.59648987],\n",
       "        [-0.4527363 ],\n",
       "        [-0.41594838],\n",
       "        [-0.70335705],\n",
       "        [-0.67077793],\n",
       "        [-0.64634986],\n",
       "        [-0.44189942],\n",
       "        [-0.52138342],\n",
       "        [-0.54285025],\n",
       "        [-0.44908395],\n",
       "        [-0.57085257],\n",
       "        [-0.48556536],\n",
       "        [-0.660339  ],\n",
       "        [-0.43196212],\n",
       "        [-0.45818895],\n",
       "        [-0.46356669],\n",
       "        [-0.45794834],\n",
       "        [-0.41258429],\n",
       "        [-0.59984693],\n",
       "        [-0.36762122],\n",
       "        [-0.38122795],\n",
       "        [-0.3751492 ],\n",
       "        [-0.43843847],\n",
       "        [-0.42971889],\n",
       "        [-0.4180674 ],\n",
       "        [-0.42360067],\n",
       "        [-0.77642565],\n",
       "        [-0.4607525 ],\n",
       "        [-0.5369058 ],\n",
       "        [-0.77687282],\n",
       "        [-0.48326652],\n",
       "        [-0.48102435],\n",
       "        [-0.63237489],\n",
       "        [-0.50443021],\n",
       "        [-0.45437735]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate for Model 3: 0.9693877551020408\n",
      "False Positive Rate for Model 3: 0.04093567251461988\n",
      "True Negative Rate for Model 3: 0.9590643274853801\n",
      "False Negative Rate for Model 3: 0.030612244897959218\n"
     ]
    }
   ],
   "source": [
    "def predict(x_test,ytest):\n",
    "    \n",
    "    y_pred =[]\n",
    "\n",
    "    n = len(y_test)\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "            y_pred.append(1/(1 + np.exp(-np.dot(np.transpose(x_test.loc[i]),wbest))))\n",
    "            \n",
    "            y_pred[i] = y_pred[i][0]\n",
    "    return y_pred\n",
    "y_pred = predict(x_test,y_test)\n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "\n",
    "#Performance metrics for this value of gamma\n",
    "\n",
    "tpr, fpr, tnr, fnr = metrics(y_pred, y_test)\n",
    "\n",
    "print(f'True Positive Rate for Model 3: {tpr}')\n",
    "print(f'False Positive Rate for Model 3: {fpr}')\n",
    "print(f'True Negative Rate for Model 3: {tnr}')\n",
    "print(f'False Negative Rate for Model 3: {fnr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  t   | TPR   | FPR   | TNR   | FNR  |\n",
      " 0.1  | 1.00  | 1.00  | 0.00  | 0.00 |\n",
      "\n",
      " 0.2  | 1.00  | 1.00  | 0.00  | 0.00 |\n",
      "\n",
      " 0.3  | 1.00  | 1.00  | 0.00  | 0.00 |\n",
      "\n",
      " 0.4  | 1.00  | 0.80  | 0.20  | 0.00 |\n",
      "\n",
      " 0.5  | 0.97  | 0.04  | 0.96  | 0.03 |\n",
      "\n",
      " 0.6  | 0.50  | 0.00  | 1.00  | 0.50 |\n",
      "\n",
      " 0.7  | 0.09  | 0.00  | 1.00  | 0.91 |\n",
      "\n",
      " 0.8  | 0.00  | 0.00  | 1.00  | 1.00 |\n",
      "\n",
      " 0.9  | 0.00  | 0.00  | 1.00  | 1.00 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "print(f'  t   | TPR   | FPR   | TNR   | FNR  |')\n",
    "for i in threshold: \n",
    "\n",
    "    y_pred = predict(x_test,y_test)\n",
    "    \n",
    "    for j in range(len(y_pred)):\n",
    "        \n",
    "        if y_pred[j] >= i:\n",
    "            y_pred[j] = 1\n",
    "        else:\n",
    "            y_pred[j] = 0 \n",
    "    tpr, fpr, tnr, fnr = metrics(y_pred, y_test)\n",
    "    print(f' {i}  | {tpr:.2f}  | {fpr:.2f}  | {tnr:.2f}  | {fnr:.2f} |\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
